from fastapi import FastAPI, HTTPException, Query
from fastapi.middleware.cors import CORSMiddleware
from database import db
from gemini_service import gemini_service
from ml_service import ml_service
from typing import Optional
import uvicorn
import numpy as np

app = FastAPI(
    title="LGS Soru Tahmin API",
    description="AI Destekli LGS Ä°ngilizce Soru Tahmin Sistemi",
    version="1.0.0"
)

# CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

@app.on_event("startup")
async def startup_event():
    """Uygulama baÅŸlatÄ±ldÄ±ÄŸÄ±nda veritabanÄ± baÄŸlantÄ±sÄ±nÄ± kur"""
    if not db.connect():
        raise Exception("VeritabanÄ± baÄŸlantÄ±sÄ± kurulamadÄ±!")

@app.on_event("shutdown")
async def shutdown_event():
    """Uygulama kapatÄ±ldÄ±ÄŸÄ±nda veritabanÄ± baÄŸlantÄ±sÄ±nÄ± kapat"""
    db.disconnect()

@app.get("/")
def read_root():
    """Ana sayfa"""
    return {
        "message": "LGS Soru Tahmin API'sine HoÅŸ Geldiniz!",
        "version": "1.0.0",
        "docs": "/docs"
    }

@app.get("/api/questions")
def get_questions(
    year: Optional[int] = Query(None, description="YÄ±l filtresi"),
    topic: Optional[str] = Query(None, description="Konu filtresi"),
    limit: Optional[int] = Query(50, description="Soru sayÄ±sÄ± sÄ±nÄ±rÄ±")
):
    """
    GeÃ§miÅŸ Ã§Ä±kmÄ±ÅŸ sorularÄ± getir
    
    - **year**: Belirli yÄ±l (opsiyonel)
    - **topic**: Belirli konu (opsiyonel)
    - **limit**: Maksimum soru sayÄ±sÄ± (varsayÄ±lan: 50)
    """
    try:
        # Database baÄŸlantÄ±sÄ±nÄ± kontrol et
        if not db.connection:
            db.connect()
        
        # Base query
        query = "SELECT * FROM lgs_questions WHERE 1=1"
        params = []
        
        # Filters
        if year:
            query += " AND year = %s"
            params.append(year)
        
        if topic:
            query += " AND topic ILIKE %s"
            params.append(f"%{topic}%")
        
        # Order and limit
        query += " ORDER BY year DESC, question_number ASC LIMIT %s"
        params.append(limit)
        
        # Execute
        questions = db.execute_query(query, params)
        
        # Null check
        if questions is None:
            return {
                "success": False,
                "message": "VeritabanÄ± sorgusu baÅŸarÄ±sÄ±z",
                "data": [],
                "count": 0
            }
        
        if not questions:
            return {
                "success": True,
                "message": "Soru bulunamadÄ±",
                "data": [],
                "count": 0
            }
        
        questions_list = [dict(q) for q in questions]
        
        return {
            "success": True,
            "message": f"{len(questions_list)} soru bulundu",
            "data": questions_list,
            "count": len(questions_list)
        }
        
    except Exception as e:
        return {
            "success": False,
            "message": f"Hata: {str(e)}",
            "data": [],
            "count": 0
        }

@app.post("/api/predict")
def predict_questions(target_year: Optional[int] = Query(2025, description="Tahmin yÄ±lÄ±")):
    """
    Soru daÄŸÄ±lÄ±mÄ± tahmini
    
    - **target_year**: Hangi yÄ±l iÃ§in tahmin (varsayÄ±lan: 2025)
    """
    try:
        prediction = gemini_service.predict_question_distribution(target_year)
        
        return {
            "success": True,
            "message": f"{target_year} yÄ±lÄ± tahmini",
            "data": prediction
        }
        
    except Exception as e:
        return {
            "success": False,
            "message": f"Tahmin hatasÄ±: {str(e)}",
            "data": {}
        }

@app.post("/api/generate")
def generate_questions(
    topic: Optional[str] = Query(None, description="Belirli konu (opsiyonel)"),
    count: Optional[int] = Query(5, description="Soru sayÄ±sÄ±", ge=1, le=10),
    difficulty: Optional[str] = Query("orta", description="Zorluk: kolay, orta, zor")
):
    """
    Soru Ã¼retme
    
    - **topic**: Belirli konu iÃ§in soru Ã¼ret (boÅŸ bÄ±rakÄ±rsan genel)
    - **count**: KaÃ§ soru Ã¼retilecek (1-10)
    - **difficulty**: Zorluk seviyesi
    """
    try:
        if difficulty not in ["kolay", "orta", "zor"]:
            return {
                "success": False,
                "message": "Zorluk 'kolay', 'orta' veya 'zor' olmalÄ±",
                "data": {}
            }
        
        if topic:
            # Belirli konuda soru Ã¼ret
            questions = gemini_service.generate_questions(topic, count, difficulty)
            message = f"{topic} konusunda {len(questions)} soru Ã¼retildi"
        else:
            # Genel karma soru Ã¼ret
            questions = gemini_service.generate_mixed_questions(count)
            message = f"Karma {len(questions)} soru Ã¼retildi"
        
        return {
            "success": True,
            "message": message,
            "data": {
                "topic": topic or "Karma",
                "difficulty": difficulty,
                "count": len(questions),
                "questions": questions
            }
        }
        
    except Exception as e:
        return {
            "success": False,
            "message": f"Soru Ã¼retme hatasÄ±: {str(e)}",
            "data": {}
        }

@app.post("/api/generate-exam")
def generate_exam(
    question_count: Optional[int] = Query(10, description="SÄ±nav soru sayÄ±sÄ±", ge=5, le=20)
):
    """
    GerÃ§ekÃ§i LGS Ä°ngilizce sÄ±navÄ± Ã¼ret
    
    - **question_count**: SÄ±nav soru sayÄ±sÄ± (5-20 arasÄ±)
    - Konu daÄŸÄ±lÄ±mÄ± geÃ§miÅŸ yÄ±llardaki gerÃ§ek oranlarla aynÄ±
    - Ä°statistik tablosundan hÄ±zlÄ± hesaplama
    """
    try:
        exam_result = gemini_service.generate_exam_questions(question_count)
        
        if not exam_result.get('success', False):
            return {
                "success": False,
                "message": "SÄ±nav Ã¼retilemedi",
                "data": {}
            }
        
        return {
            "success": True,
            "message": f"{question_count} soruluk LGS Ä°ngilizce sÄ±navÄ± Ã¼retildi",
            "data": {
                "exam_info": exam_result['exam_metadata'],
                "questions": exam_result['questions'],
                "total_questions": len(exam_result['questions'])
            }
        }
        
    except Exception as e:
        return {
            "success": False,
            "message": f"SÄ±nav Ã¼retme hatasÄ±: {str(e)}",
            "data": {}
        }

@app.get("/api/statistics")
def get_statistics_data(
    year: Optional[int] = Query(None, description="Belirli yÄ±l filtresi"),
    topic: Optional[str] = Query(None, description="Belirli konu filtresi"),
    limit: Optional[int] = Query(50, description="SonuÃ§ sayÄ±sÄ± sÄ±nÄ±rÄ±")
):
    """
    LGS Ä°statistik tablosundaki verileri getir
    
    - **year**: Belirli yÄ±l (opsiyonel)
    - **topic**: Belirli konu (opsiyonel)
    - **limit**: Maksimum sonuÃ§ sayÄ±sÄ± (varsayÄ±lan: 50)
    """
    try:
        # Database baÄŸlantÄ±sÄ±nÄ± kontrol et
        if not db.connection:
            db.connect()
        
        # Base query
        query = """
            SELECT topic, year, question_count, percentage, 
                   total_questions_in_year, created_at, updated_at
            FROM lgs_statistics 
            WHERE 1=1
        """
        params = []
        
        # Filters
        if year:
            query += " AND year = %s"
            params.append(year)
        
        if topic:
            query += " AND topic ILIKE %s"
            params.append(f"%{topic}%")
        
        # Order and limit
        query += " ORDER BY year DESC, question_count DESC LIMIT %s"
        params.append(limit)
        
        # Execute
        statistics = db.execute_query(query, params)
        
        if statistics is None:
            return {
                "success": False,
                "message": "Ä°statistik tablosu sorgulanamadÄ± - lÃ¼tfen create_statistics_table.py Ã§alÄ±ÅŸtÄ±rÄ±n",
                "data": [],
                "count": 0
            }
        
        if not statistics:
            return {
                "success": True,
                "message": "Ä°statistik bulunamadÄ±",
                "data": [],
                "count": 0
            }
        
        stats_list = [dict(stat) for stat in statistics]
        
        return {
            "success": True,
            "message": f"{len(stats_list)} istatistik kaydÄ± bulundu",
            "data": stats_list,
            "count": len(stats_list)
        }
        
    except Exception as e:
        return {
            "success": False,
            "message": f"Ä°statistik getirme hatasÄ±: {str(e)}",
            "data": [],
            "count": 0
        }

@app.get("/api/statistics/summary")
def get_statistics_summary():
    """
    LGS Ä°statistik Ã¶zeti - Konu bazÄ±nda toplam veriler
    """
    try:
        # Database baÄŸlantÄ±sÄ±nÄ± kontrol et
        if not db.connection:
            db.connect()
        
        # Konu bazÄ±nda Ã¶zet
        topic_summary_query = """
            SELECT topic, 
                   COUNT(DISTINCT year) as years_appeared,
                   SUM(question_count) as total_questions,
                   ROUND(AVG(percentage), 2) as avg_percentage,
                   MIN(year) as first_year,
                   MAX(year) as last_year
            FROM lgs_statistics
            GROUP BY topic
            ORDER BY total_questions DESC
        """
        
        topic_summary = db.execute_query(topic_summary_query)
        
        # YÄ±l bazÄ±nda Ã¶zet
        year_summary_query = """
            SELECT year, 
                   COUNT(DISTINCT topic) as topic_count,
                   SUM(question_count) as total_questions,
                   MAX(total_questions_in_year) as total_questions_in_year
            FROM lgs_statistics
            GROUP BY year
            ORDER BY year DESC
        """
        
        year_summary = db.execute_query(year_summary_query)
        
        # Genel istatistikler
        general_stats_query = """
            SELECT 
                COUNT(*) as total_records,
                COUNT(DISTINCT topic) as unique_topics,
                COUNT(DISTINCT year) as unique_years,
                SUM(question_count) as total_questions,
                MIN(year) as earliest_year,
                MAX(year) as latest_year
            FROM lgs_statistics
        """
        
        general_stats = db.execute_single_query(general_stats_query)
        
        if topic_summary is None or year_summary is None or general_stats is None:
            return {
                "success": False,
                "message": "Ä°statistik tablosu bulunamadÄ± - lÃ¼tfen create_statistics_table.py Ã§alÄ±ÅŸtÄ±rÄ±n",
                "data": {}
            }
        
        return {
            "success": True,
            "message": "Ä°statistik Ã¶zeti baÅŸarÄ±yla getirildi",
            "data": {
                "general_statistics": dict(general_stats) if general_stats else {},
                "topic_summary": [dict(row) for row in topic_summary] if topic_summary else [],
                "year_summary": [dict(row) for row in year_summary] if year_summary else []
            }
        }
        
    except Exception as e:
        return {
            "success": False,
            "message": f"Ä°statistik Ã¶zeti hatasÄ±: {str(e)}",
            "data": {}
        }

@app.get("/api/statistics/distribution")
def get_topic_distribution_data():
    """
    Konu daÄŸÄ±lÄ±m verilerini getir - SÄ±nav Ã¼retme iÃ§in kullanÄ±lan veriler
    """
    try:
        # Database baÄŸlantÄ±sÄ±nÄ± kontrol et
        if not db.connection:
            db.connect()
        
        # Son 5 yÄ±lÄ±n konu daÄŸÄ±lÄ±mÄ±
        distribution_query = """
            SELECT topic, 
                   ROUND(AVG(percentage), 1) as avg_percentage,
                   SUM(question_count) as total_questions,
                   COUNT(DISTINCT year) as years_appeared,
                   ARRAY_AGG(DISTINCT year ORDER BY year DESC) as years
            FROM lgs_statistics 
            WHERE year >= 2020
            GROUP BY topic 
            HAVING SUM(question_count) >= 3
            ORDER BY total_questions DESC
        """
        
        distribution_data = db.execute_query(distribution_query)
        
        if distribution_data is None:
            return {
                "success": False,
                "message": "DaÄŸÄ±lÄ±m verisi bulunamadÄ± - lÃ¼tfen create_statistics_table.py Ã§alÄ±ÅŸtÄ±rÄ±n",
                "data": []
            }
        
        if not distribution_data:
            return {
                "success": True,
                "message": "DaÄŸÄ±lÄ±m verisi bulunamadÄ±",
                "data": []
            }
        
        distribution_list = [dict(row) for row in distribution_data]
        
        # Toplam yÃ¼zde hesapla
        total_percentage = sum([float(row['avg_percentage']) for row in distribution_list])
        
        return {
            "success": True,
            "message": f"{len(distribution_list)} konu daÄŸÄ±lÄ±mÄ± bulundu",
            "data": {
                "topic_distribution": distribution_list,
                "total_percentage": round(total_percentage, 1),
                "based_on_years": "2020+",
                "note": "Bu veriler sÄ±nav Ã¼retme algoritmasÄ±nda kullanÄ±lÄ±r"
            }
        }
        
    except Exception as e:
        return {
            "success": False,
            "message": f"DaÄŸÄ±lÄ±m verisi hatasÄ±: {str(e)}",
            "data": {}
        }

# ============================================
# ML MODEL ENDPOINTLERÄ° - YENÄ°!
# ============================================

@app.post("/api/ml/train")
def train_ml_model(
    topic: Optional[str] = Query(None, description="Belirli konu iÃ§in eÄŸit (opsiyonel)"),
    limit: Optional[int] = Query(200, description="EÄŸitim verisi sayÄ±sÄ±", ge=50, le=500),
    model_type: Optional[str] = Query("ensemble", description="Model tipi: random_forest, gradient_boosting, veya ensemble")
):
    """
    ğŸ¤– ML Modelini EÄŸit
    
    DB'deki geÃ§miÅŸ LGS sorularÄ±nÄ± kullanarak modeli eÄŸitir.
    
    - **topic**: Belirli konu iÃ§in eÄŸit (boÅŸ bÄ±rakÄ±rsan tÃ¼m konular)
    - **limit**: KaÃ§ soru ile eÄŸitilecek (50-500 arasÄ±)
    - **model_type**: Model tipi
    
    **Model Tipleri:**
    - naive_bayes: Az veri iÃ§in EN Ä°YÄ°! (70 soru iÃ§in Ã¶nerilen) â­
    - random_forest: HÄ±zlÄ±, dengeli (200+ soru iÃ§in)
    - gradient_boosting: YÃ¼ksek accuracy (200+ soru iÃ§in)
    - ensemble: 3 model birleÅŸimi (500+ soru iÃ§in)
    
    EÄŸitim sonrasÄ± model accuracy, F1 score ve istatistikler dÃ¶ner.
    """
    try:
        if model_type not in ["random_forest", "gradient_boosting", "ensemble"]:
            return {
                "success": False,
                "message": "model_type 'random_forest', 'gradient_boosting' veya 'ensemble' olmalÄ±",
                "stats": {}
            }
        
        result = ml_service.train_model(topic=topic, limit=limit, model_type=model_type)
        return result
        
    except Exception as e:
        return {
            "success": False,
            "message": f"Model eÄŸitim hatasÄ±: {str(e)}",
            "stats": {}
        }

@app.post("/api/ml/generate")
def generate_with_ml_model(
    topic: Optional[str] = Query(None, description="Belirli konu (opsiyonel)"),
    count: Optional[int] = Query(5, description="Soru sayÄ±sÄ±", ge=1, le=20),
    difficulty: Optional[str] = Query("orta", description="Zorluk: kolay, orta, zor")
):
    """
    ğŸ¯ EÄŸitilmiÅŸ Modelle Soru Ãœret
    
    Ã–nceden eÄŸitilmiÅŸ ML modeli kullanarak yeni sorular Ã¼retir.
    **DB'ye kaydetmez**, sadece Ã¼retir ve dÃ¶ner.
    
    - **topic**: Belirli konu iÃ§in soru Ã¼ret (boÅŸ bÄ±rakÄ±rsan karma)
    - **count**: KaÃ§ soru Ã¼retilecek (1-20)
    - **difficulty**: Zorluk seviyesi
    
    âš ï¸ Not: Ã–nce /api/ml/train endpoint'ini Ã§aÄŸÄ±rmalÄ±sÄ±nÄ±z!
    
    DÃ¶nen veri:
    - Ãœretilen sorular
    - Model accuracy
    - BaÅŸarÄ± oranÄ±
    - EÄŸitim istatistikleri
    """
    try:
        if difficulty not in ["kolay", "orta", "zor"]:
            return {
                "success": False,
                "message": "Zorluk 'kolay', 'orta' veya 'zor' olmalÄ±",
                "questions": [],
                "model_info": {}
            }
        
        result = ml_service.generate_questions_with_model(
            topic=topic,
            count=count,
            difficulty=difficulty
        )
        
        return result
        
    except Exception as e:
        return {
            "success": False,
            "message": f"Soru Ã¼retme hatasÄ±: {str(e)}",
            "questions": [],
            "model_info": {}
        }

@app.get("/api/ml/status")
def get_ml_model_status():
    """
    ğŸ“Š ML Model Durumu
    
    Modelin eÄŸitim durumunu, accuracy'sini ve istatistiklerini gÃ¶sterir.
    
    DÃ¶nen bilgiler:
    - Model eÄŸitildi mi?
    - Model accuracy (%)
    - EÄŸitim verisi boyutu
    - Veri kalitesi skoru
    - Son eÄŸitim tarihi
    """
    try:
        status = ml_service.get_model_status()
        
        return {
            "success": True,
            "message": "Model durumu baÅŸarÄ±yla getirildi",
            "data": status
        }
        
    except Exception as e:
        return {
            "success": False,
            "message": f"Model durumu getirme hatasÄ±: {str(e)}",
            "data": {}
        }

@app.post("/api/ml/train-and-generate")
def train_and_generate_questions(
    topic: Optional[str] = Query(None, description="Belirli konu (opsiyonel)"),
    training_limit: Optional[int] = Query(200, description="EÄŸitim verisi sayÄ±sÄ±", ge=50, le=500),
    question_count: Optional[int] = Query(5, description="Ãœretilecek soru sayÄ±sÄ±", ge=1, le=20),
    difficulty: Optional[str] = Query("orta", description="Zorluk: kolay, orta, zor"),
    model_type: Optional[str] = Query("ensemble", description="Model tipi: random_forest, gradient_boosting, veya ensemble")
):
    """
    ğŸš€ Tek Seferde: EÄŸit + Ãœret
    
    GerÃ§ek ML modelini eÄŸitir (Random Forest) ve hemen ardÄ±ndan yeni sorular Ã¼retir.
    **DB'ye kaydetmez**, sadece Ã¼retir.
    
    - **topic**: Belirli konu (boÅŸ bÄ±rakÄ±rsan tÃ¼m konular)
    - **training_limit**: KaÃ§ soru ile eÄŸitilecek (50-500)
    - **question_count**: KaÃ§ soru Ã¼retilecek (1-20)
    - **difficulty**: Zorluk seviyesi
    
    DÃ¶nen veri:
    - EÄŸitim istatistikleri (TF-IDF, Random Forest)
    - Model accuracy (gerÃ§ek ML accuracy)
    - Ãœretilen sorular
    - BaÅŸarÄ± oranÄ±
    """
    try:
        # 1. Modeli eÄŸit
        training_result = ml_service.train_model(topic=topic, limit=training_limit, model_type=model_type)
        
        if not training_result.get('success', False):
            return {
                "success": False,
                "message": "Model eÄŸitilemedi",
                "training_result": training_result,
                "questions": []
            }
        
        # 2. Soru Ã¼ret
        generation_result = ml_service.generate_questions_with_model(
            topic=topic,
            count=question_count,
            difficulty=difficulty
        )
        
        if not generation_result.get('success', False):
            return {
                "success": False,
                "message": "Sorular Ã¼retilemedi",
                "training_result": training_result,
                "generation_result": generation_result
            }
        
        # 3. BirleÅŸtirilmiÅŸ sonuÃ§
        return {
            "success": True,
            "message": f"ML Model eÄŸitildi ve {len(generation_result['questions'])} soru Ã¼retildi",
            "training_stats": training_result['stats'],
            "model_info": generation_result['model_info'],
            "questions": generation_result['questions'],
            "generation_stats": generation_result.get('generation_stats', {}),
            "summary": {
                "training_data_size": training_result['stats'].get('total_questions', 0),
                "model_type": training_result['stats'].get('model_type', 'Random Forest'),
                "model_accuracy": generation_result['model_info'].get('accuracy', 0),
                "generation_success_rate": generation_result['model_info'].get('generation_success_rate', 0),
                "data_quality": generation_result['model_info'].get('data_quality', 0),
                "generated_count": len(generation_result['questions']),
                "top_features": generation_result['model_info'].get('top_features', [])
            }
        }
        
    except Exception as e:
        return {
            "success": False,
            "message": f"EÄŸitim ve Ã¼retim hatasÄ±: {str(e)}",
            "training_result": {},
            "questions": []
        }

@app.post("/api/ml/predict-topic")
def predict_question_topic(
    question_text: str = Query(..., description="Soru metni")
):
    """
    ğŸ”® Soru Metninden Konu Tahmini
    
    EÄŸitilmiÅŸ ML modeli kullanarak soru metninden konu tahmini yapar.
    
    - **question_text**: Tahmin edilecek soru metni
    
    DÃ¶nen veri:
    - Tahmin edilen konu
    - GÃ¼ven skoru (%)
    - Top 3 tahmin
    """
    try:
        prediction = ml_service.predict_topic(question_text)
        
        if 'error' in prediction:
            return {
                "success": False,
                "message": prediction['error'],
                "prediction": {}
            }
        
        return {
            "success": True,
            "message": "Konu tahmini baÅŸarÄ±lÄ±",
            "prediction": prediction,
            "question_text": question_text
        }
        
    except Exception as e:
        return {
            "success": False,
            "message": f"Tahmin hatasÄ±: {str(e)}",
            "prediction": {}
        }

@app.get("/api/ml/debug")
def debug_ml_model():
    """
    ğŸ”§ ML Model Debug Bilgileri
    
    Model durumu ve debug bilgilerini gÃ¶sterir.
    """
    try:
        import sys
        import sklearn
        
        return {
            "success": True,
            "debug_info": {
                "python_version": sys.version,
                "sklearn_version": sklearn.__version__,
                "numpy_version": np.__version__,
                "model_status": ml_service.get_model_status(),
                "model_files_exist": {
                    "classifier": (ml_service.model_dir / "topic_classifier.pkl").exists(),
                    "vectorizer": (ml_service.model_dir / "vectorizer.pkl").exists(),
                    "encoder": (ml_service.model_dir / "label_encoder.pkl").exists()
                }
            }
        }
    except Exception as e:
        return {
            "success": False,
            "message": f"Debug hatasÄ±: {str(e)}"
        }

if __name__ == "__main__":
    uvicorn.run("main:app", host="0.0.0.0", port=8000, reload=True)